{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "<module 'torch.backends.mps' from '/Users/oniichan/anaconda3/envs/its530_py38/lib/python3.8/site-packages/torch/backends/mps/__init__.py'>\n",
      "4902312704\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.mps)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    # get number of cuda devices\n",
    "    print(f\"devices: {torch.cuda.device_count()}\")\n",
    "    print(f\"device:  {torch.cuda.get_device_name()}\")\n",
    "    print(f\"device0: {torch.cuda.get_device_properties(0)}\")\n",
    "    print(f\"{torch.cuda.memory_summary()}\")\n",
    "elif torch.backends.mps is not None:\n",
    "    device = torch.device('mps')\n",
    "    print(f\"{torch.mps.current_allocated_memory()}\")\n",
    "    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    # print a warning that cpu is being used\n",
    "    print(\"Warning: Running on CPU. This will be slow.\")\n",
    "print(f\"{device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "\n",
    "    def __init__(self, head_size, block_size, n_embd, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.key   = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
    "\n",
    "        tril_def = torch.tril( torch.ones(block_size, block_size) )  ## [40, 40]\n",
    "        \n",
    "        self.register_buffer(\n",
    "                  'tril', \n",
    "                  tril_def\n",
    "               )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        B, T, E = x.shape   ## [batch_size, 40, 512]\n",
    "        \n",
    "        k = self.key(   x )            ## k = (B, T, 64)\n",
    "        q = self.query( x )            ## q = (B, T, 64)\n",
    "\n",
    "        E2 = 64     ## I think this is 64 and not 512\n",
    "        ## (B, T, E) @ (B, E, T)  -> (B, T, T)\n",
    "        wei = q @ k.transpose(-2, -1) * E2 ** -0.5        \n",
    "        \n",
    "        wei = wei.masked_fill(\n",
    "                      self.tril[:T, :T] == 0, \n",
    "                      float('-inf')\n",
    "        )   \n",
    "        \n",
    "        ## (B, T, T)\n",
    "        wei = F.softmax( wei, dim= -1 )         ## (B, T, T)\n",
    "        wei = self.dropout(   wei   )\n",
    "        \n",
    "        ## perform weighted aggregation of values\n",
    "        \n",
    "        v   = self.value(  x  )   ## x = (B, 40, E)\n",
    "        out = wei @ v             ## (B, T, T) @ (B, T, 64) -> (B, T, 64)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embd, dropout):         ## 512\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),      ## [512, 4*512]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),      ## [4*512, 512]\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, n_head, head_size, block_size, n_embd, dropout):    ## (8, 64)\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(  [ Head(head_size, block_size, n_embd, dropout) for _ in range(n_head) ] )\n",
    "        self.proj  = nn.Linear(n_embd, n_embd)   ## 512, 512\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.cat(   [ h(x) for h in self.heads ], dim = -1   )\n",
    "        out = self.proj(  out   )\n",
    "        out = self.dropout(   out   )\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_head, block_size, n_embd, dropout):     ## (512, 8)\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head        ## 64\n",
    "        self.sa   = MultiHeadAttention(n_head, head_size, block_size, n_embd, dropout)\n",
    "        self.ffwd = FeedForward( n_embd, dropout)    ## 512\n",
    "        self.ln1  = nn.LayerNorm(n_embd)\n",
    "        self.ln2  = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(     self.ln1(x)      )\n",
    "        x = x + self.ffwd(   self.ln2(x)      )\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, n_embd, block_size, n_layer, n_head, dropout):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(112, n_embd)   ## [65, 512]\n",
    "        self.pos_emb_table = nn.Embedding(block_size, n_embd)     ## [block, 512]\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "                *[ Block(n_head, block_size, n_embd, dropout) for _ in range(n_layer) ]\n",
    "        )\n",
    "        \n",
    "        self.ln_f    = nn.LayerNorm(  n_embd    )        \n",
    "        self.lm_ffw_head = nn.Linear(n_embd, 112)  ## [512, 65] # FFW Layer\n",
    "        self.block_size = block_size\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape     ## (Batch, 40)\n",
    "        ## ids and targets are both (B, T) tensors of integers\n",
    "        \n",
    "        tok_emb = self.token_embedding_table(idx)      \n",
    "        pos_emb = self.pos_emb_table(torch.arange(T, device=device))  \n",
    "        \n",
    "        x = tok_emb + pos_emb    ## [B, T, E] or [64, 40, 512]\n",
    "\n",
    "        ## This is the architecture\n",
    "        x = self.blocks(  x  )   ## (B, T, E)        \n",
    "        x = self.ln_f(    x  )   ## (B, T, E)   ## norm\n",
    "        logits = self.lm_ffw_head(x)         ## [B, 40, 65] \n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, E  = logits.shape\n",
    "            logits  = logits.view( B*T, E)\n",
    "            targets = targets.view(B*T)\n",
    "            loss    = F.cross_entropy(logits, targets)\n",
    "        return logits#, loss\n",
    "        \n",
    "    def generate(self, idx, max_new_tokens):    ## idx is (B, T)\n",
    "        for _ in range(max_new_tokens):\n",
    "            ## crop idx to the last block_size tokens\n",
    "            # idx_cond, _loss\n",
    "            idx_cond = idx[:, -self.block_size:]\n",
    "            logits = self(idx_cond)    ## ## get preds\n",
    "            logits = logits[:, -1, :]    ## focus on last one (B, E)\n",
    "            probs = F.softmax(logits, dim= -1)    ## (B, E) get probs\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)     ## (B, 1) selected\n",
    "            idx = torch.cat(  (idx, idx_next), dim=1  )   ## (B, T+1) append sample to running sequence\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, stride=128, window=None, files=None):\n",
    "        self.files = files\n",
    "\n",
    "        max_length = 1024\n",
    "        dataset = []\n",
    "        df = pd.read_csv('exchange_rate.txt', header=None)\n",
    "        df = df.dropna() # i think axis=1 drops columns\n",
    "        # drop any columns with str\n",
    "        df = df.drop(df.select_dtypes(['object']), axis=1)\n",
    "\n",
    "        norm_df = (df - df.min()) * (50_257-2) / ( df.max() - df.min() )\n",
    "        n_cols = 1#norm_df.shape[1]\n",
    "\n",
    "        tokens = norm_df.values.flatten().astype(int)\n",
    "        \n",
    "        # Create sequences with sliding window\n",
    "        samples = 0\n",
    "        for i in range(0, len(tokens) - max_length, stride):\n",
    "            sequence = tokens[i:i + max_length]\n",
    "            if len(sequence) == max_length:\n",
    "                input_sequence = np.array(sequence[:-n_cols])#, dtype=np.int64) # dont include the last token\n",
    "                target_sequence = np.array(sequence[n_cols:])#, dtype=np.int64) # dont include the first token\n",
    "                \n",
    "                dataset.append({\n",
    "                    'input_ids': input_sequence,\n",
    "                    'labels': target_sequence\n",
    "                })\n",
    "            samples += 1\n",
    "            if samples > 512: # 1024\n",
    "                print('max samples from file')\n",
    "                break\n",
    "        print('samples:', samples)\n",
    "\n",
    "        self.data = dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        # print(item['input_ids'].shape, item['labels'].shape, torch.ones_like(torch.tensor(item['input_ids'])).shape)\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(item['input_ids']).to(device),\n",
    "            'labels': torch.tensor(item['labels']).to(device),\n",
    "            'attention_mask': torch.ones_like(torch.tensor(item['input_ids'])).to(device)\n",
    "        }\n",
    "    \n",
    "    def min(self):\n",
    "        if len(self.files) == 1:\n",
    "            return self.min_val\n",
    "        else:\n",
    "            raise Exception(\"Multiple files, use min_val from each file\")\n",
    "    \n",
    "    def max(self):\n",
    "        if len(self.files) == 1:\n",
    "            return self.max_val\n",
    "        else:\n",
    "            raise Exception(\"Multiple files, use max_val from each file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## every id for a given token is embedded to vector of this size\n",
    "n_embd            = 768        # GPT-2\n",
    "n_head            = 12         # GPT-2\n",
    "n_layer           = 12         # GPT-2\n",
    "dropout           = 0.1        # GPT-2\n",
    "\n",
    "learning_rate     = 2.5e-4     # GPT-2\n",
    "vocab_size        = 50_257     # GPT-2 50_257\n",
    "block_size        = 1024       # GPT-2 (context) ## N tokens in sequence\n",
    "\n",
    "batch_size        = 2\n",
    "# max_iters         = 512\n",
    "eval_interval     = 512\n",
    "# eval_iters        = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(\n",
    "                    n_embd=n_embd,\n",
    "                    block_size=block_size,\n",
    "                    n_layer=n_layer,\n",
    "                    n_head=n_head,\n",
    "                    dropout=dropout\n",
    "                ).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging Face Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "from transformers.modeling_outputs import CausalLMOutput\n",
    "\n",
    "class GPTConfig(PretrainedConfig):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block_size=40,\n",
    "        vocab_size=98,\n",
    "        n_embd=512,\n",
    "        n_head=8,\n",
    "        n_layer=6,\n",
    "        dropout=0.2,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_embd = n_embd\n",
    "        self.n_head = n_head\n",
    "        self.n_layer = n_layer\n",
    "        self.dropout = dropout\n",
    "\n",
    "class GPTModelForTrainer(PreTrainedModel):\n",
    "    config_class = GPTConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        # keep model inside because we cant pass it in\n",
    "        self.model = GPTModel(\n",
    "                    n_embd=n_embd,\n",
    "                    block_size=block_size,\n",
    "                    n_layer=n_layer,\n",
    "                    n_head=n_head,\n",
    "                    dropout=dropout\n",
    "                )\n",
    "        \n",
    "    def forward(self, input_ids, labels=None, **kwargs):\n",
    "        logits = self.model(input_ids)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            shift_logits = logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            \n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)),\n",
    "                          shift_labels.view(-1))\n",
    "            \n",
    "        return CausalLMOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: 467\n"
     ]
    }
   ],
   "source": [
    "train_dataset = GPTDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf6b9505e5e4ad0bc3c1acfb58a603e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/702 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 41\u001b[0m\n\u001b[1;32m     33\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     34\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel_for_trainer,\n\u001b[1;32m     35\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     36\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# eval_dataset=eval_dataset,\u001b[39;00m\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/its530_py38/lib/python3.8/site-packages/transformers/trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/its530_py38/lib/python3.8/site-packages/transformers/trainer.py:2003\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1998\u001b[0m     _grad_norm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\n\u001b[1;32m   1999\u001b[0m         amp\u001b[38;5;241m.\u001b[39mmaster_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer),\n\u001b[1;32m   2000\u001b[0m         args\u001b[38;5;241m.\u001b[39mmax_grad_norm,\n\u001b[1;32m   2001\u001b[0m     )\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2003\u001b[0m     _grad_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2005\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_grad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2006\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2008\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2009\u001b[0m     is_accelerate_available()\n\u001b[1;32m   2010\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2011\u001b[0m ):\n\u001b[1;32m   2012\u001b[0m     grad_norm \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_global_grad_norm()\n",
      "File \u001b[0;32m~/anaconda3/envs/its530_py38/lib/python3.8/site-packages/accelerate/accelerator.py:2102\u001b[0m, in \u001b[0;36mAccelerator.clip_grad_norm_\u001b[0;34m(self, parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m   2100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_gradients()\n\u001b[0;32m-> 2102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/its530_py38/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py:59\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m             norms\u001b[38;5;241m.\u001b[39mextend([torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(g, norm_type) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads])\n\u001b[1;32m     61\u001b[0m     total_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(torch\u001b[38;5;241m.\u001b[39mstack([norm\u001b[38;5;241m.\u001b[39mto(first_device) \u001b[38;5;28;01mfor\u001b[39;00m norm \u001b[38;5;129;01min\u001b[39;00m norms]), norm_type)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_if_nonfinite \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlogical_or(total_norm\u001b[38;5;241m.\u001b[39misnan(), total_norm\u001b[38;5;241m.\u001b[39misinf()):\n",
      "File \u001b[0;32m~/anaconda3/envs/its530_py38/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py:59\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m             norms\u001b[38;5;241m.\u001b[39mextend([\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads])\n\u001b[1;32m     61\u001b[0m     total_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(torch\u001b[38;5;241m.\u001b[39mstack([norm\u001b[38;5;241m.\u001b[39mto(first_device) \u001b[38;5;28;01mfor\u001b[39;00m norm \u001b[38;5;129;01min\u001b[39;00m norms]), norm_type)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_if_nonfinite \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlogical_or(total_norm\u001b[38;5;241m.\u001b[39misnan(), total_norm\u001b[38;5;241m.\u001b[39misinf()):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt_model\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    # per_device_eval_batch_size=batch_size,\n",
    "    # eval_steps=eval_interval,\n",
    "    save_steps=eval_interval,\n",
    "    save_total_limit=2,\n",
    "    warmup_steps=100,\n",
    "    learning_rate=learning_rate,\n",
    "    # fp16=True,  # if you want to use mixed precision training\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=eval_interval,\n",
    "    dataloader_pin_memory=False,\n",
    ")\n",
    "\n",
    "# Wrap the model\n",
    "config = GPTConfig(\n",
    "    block_size=block_size,\n",
    "    vocab_size=vocab_size,\n",
    "    n_embd=n_embd,\n",
    "    n_head=n_head,\n",
    "    n_layer=n_layer,\n",
    "    dropout=dropout,\n",
    ")\n",
    "\n",
    "model_for_trainer = GPTModelForTrainer(config)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_for_trainer,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    # eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModelForTrainer(\n",
       "  (model): GPTModel(\n",
       "    (token_embedding_table): Embedding(112, 768)\n",
       "    (pos_emb_table): Embedding(1024, 768)\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-11): 12 x Head(\n",
       "              (key): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-11): 12 x Head(\n",
       "              (key): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-11): 12 x Head(\n",
       "              (key): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-11): 12 x Head(\n",
       "              (key): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-11): 12 x Head(\n",
       "              (key): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-11): 12 x Head(\n",
       "              (key): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-11): 12 x Head(\n",
       "              (key): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-11): 12 x Head(\n",
       "              (key): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-11): 12 x Head(\n",
       "              (key): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-11): 12 x Head(\n",
       "              (key): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-11): 12 x Head(\n",
       "              (key): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-11): 12 x Head(\n",
       "              (key): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=64, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (lm_ffw_head): Linear(in_features=768, out_features=112, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved weights\n",
    "# Replace 'checkpoint-XXX' with the specific checkpoint you want to load\n",
    "checkpoint_path = \"./gpt_model/checkpoint-512\"  # or whatever your output_dir/checkpoint-XXX is\n",
    "model_for_trainer = GPTModelForTrainer.from_pretrained('./gpt_model/checkpoint-512')\n",
    "\n",
    "# Put model in evaluation mode if you're going to use it for inference\n",
    "model_for_trainer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024]) tensor([[24525, 22368, 25833,  ...,  2603, 20241,    79]], device='mps:0')\n",
      "start\n",
      "real tensor([22368, 25833,  5210, 39821,  4224, 20528,   268, 24225, 22312, 25770,\n",
      "         5168, 39821,  4404, 20631,    22, 24622, 23393, 25762,  6081, 39821,\n",
      "         5215, 20970,   404, 24566, 23824, 25873,  6209, 39821,  5055, 20939,\n",
      "            0, 24476], device='mps:0')\n",
      "pred tensor([22368, 25833,  5210, 39821,  4224, 20528,   268, 24225, 22312, 25770,\n",
      "         5168, 39821,  4404, 20631,    22, 24622, 23393, 25762,  6081, 39821,\n",
      "         5215, 20970,   404, 24566, 23824, 25873,  6209, 39821,  5055, 20939,\n",
      "            0, 24476], device='mps:0')\n",
      "middle (1020:1050)\n",
      "real tensor([29872, 25362,  9609, 39821,  2242, 20046,  3149, 25410, 30902, 25723,\n",
      "         9962, 39821,  2582, 20251,  3559, 25491, 31804, 25676, 10257, 39821,\n",
      "         2603, 20241,  3535], device='mps:0')\n",
      "pred tensor([29872, 25362,  9609, 39821,  2242, 20046,  3149, 25410, 30902, 25723,\n",
      "         9962, 39821,  2582, 20251,  3559, 25491, 31804, 25676, 10257, 39821,\n",
      "         2603, 20241,    79], device='mps:0')\n",
      "end\n",
      "real tensor([24509, 29553, 25105,  9664, 39821,  1989, 19933,  3149, 25020, 29872,\n",
      "        25362,  9609, 39821,  2242, 20046,  3149, 25410, 30902, 25723,  9962,\n",
      "        39821,  2582, 20251,  3559, 25491, 31804, 25676, 10257, 39821,  2603,\n",
      "        20241,  3535], device='mps:0')\n",
      "pred tensor([24509, 29553, 25105,  9664, 39821,  1989, 19933,  3149, 25020, 29872,\n",
      "        25362,  9609, 39821,  2242, 20046,  3149, 25410, 30902, 25723,  9962,\n",
      "        39821,  2582, 20251,  3559, 25491, 31804, 25676, 10257, 39821,  2603,\n",
      "        20241,    79], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.40it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real: shape: torch.Size([100]), goal val: 3535.0\n",
      "min: 20241.0, max: 20241.0, mean: 20241.0, std: 0.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Generate text\n",
    "output = model.generate(\n",
    "    train_dataset[0]['input_ids'].unsqueeze(0),\n",
    "    # max_length=512,\n",
    "    max_new_tokens=1,\n",
    "    # temperature=0.7,\n",
    "    # num_return_sequences=1,\n",
    "    # pad_token_id=vocab_size - 1,\n",
    "    # do_sample=True\n",
    ")\n",
    "\n",
    "print(output.shape, output)\n",
    "torch.set_printoptions(profile='full')\n",
    "print('start')\n",
    "print('real',train_dataset[0]['labels'][:32])\n",
    "print('pred',output[0][1:33])\n",
    "print('middle (1020:1050)')\n",
    "print('real',train_dataset[0]['labels'][1000:1050])\n",
    "print('pred',output[0][1001:1051])\n",
    "print('end')\n",
    "print('real',train_dataset[0]['labels'][-32:])\n",
    "print('pred',output[0][-32:])\n",
    "torch.set_printoptions(profile='default')\n",
    "\n",
    "# create scatter plot\n",
    "n = 100\n",
    "m = 1\n",
    "real = torch.full_like(torch.zeros(n), train_dataset[0]['labels'][-1])\n",
    "pred = torch.zeros(n)\n",
    "\n",
    "pbar = tqdm(range(0, n, m), total=n)\n",
    "for i in pbar:\n",
    "    output = model.generate(\n",
    "        train_dataset[0]['input_ids'].unsqueeze(0),\n",
    "        max_new_tokens=1,\n",
    "    )\n",
    "\n",
    "    for j in range(m): # -1\n",
    "        pred[i+j] = output[j][1023-1].cpu() # have to do this to get the value\n",
    "    pbar.update(m)\n",
    "\n",
    "# create scatter plot\n",
    "plt.scatter(range(n), real, label='real')\n",
    "plt.scatter(range(n), pred, label='pred')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame({'Predictions': pred})\n",
    "\n",
    "# Create the violin plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.violinplot(y='Predictions', data=df)\n",
    "plt.title(f\"Distribution of  Predictions\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"real: shape: {real.shape}, goal val: {real[0]}\")\n",
    "print(f\"min: {min(pred)}, max: {max(pred)}, mean: {torch.mean(pred)}, std: {torch.std(pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "its530_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
