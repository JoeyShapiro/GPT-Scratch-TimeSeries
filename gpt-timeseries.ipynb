{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<module 'torch.backends.mps' from 'C:\\\\Users\\\\joeya\\\\anaconda3\\\\envs\\\\py38-ITS520-Project\\\\lib\\\\site-packages\\\\torch\\\\backends\\\\mps\\\\__init__.py'>\n",
      "devices: 1\n",
      "device:  NVIDIA GeForce RTX 3080\n",
      "device0: _CudaDeviceProperties(name='NVIDIA GeForce RTX 3080', major=8, minor=6, total_memory=10239MB, multi_processor_count=68)\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.mps)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    # get number of cuda devices\n",
    "    print(f\"devices: {torch.cuda.device_count()}\")\n",
    "    print(f\"device:  {torch.cuda.get_device_name()}\")\n",
    "    print(f\"device0: {torch.cuda.get_device_properties(0)}\")\n",
    "    print(f\"{torch.cuda.memory_summary()}\")\n",
    "elif torch.backends.mps is not None:\n",
    "    device = torch.device('mps')\n",
    "    print(f\"{torch.mps.current_allocated_memory()}\")\n",
    "    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    # print a warning that cpu is being used\n",
    "    print(\"Warning: Running on CPU. This will be slow.\")\n",
    "print(f\"{device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "\n",
    "    def __init__(self, head_size, block_size, n_embd, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.key   = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
    "\n",
    "        tril_def = torch.tril( torch.ones(block_size, block_size) )  ## [40, 40]\n",
    "        \n",
    "        self.register_buffer(\n",
    "                  'tril', \n",
    "                  tril_def\n",
    "               )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        B, T, E = x.shape   ## [batch_size, 40, 512]\n",
    "        \n",
    "        k = self.key(   x )            ## k = (B, T, 64)\n",
    "        q = self.query( x )            ## q = (B, T, 64)\n",
    "\n",
    "        E2 = 64     ## I think this is 64 and not 512\n",
    "        ## (B, T, E) @ (B, E, T)  -> (B, T, T)\n",
    "        wei = q @ k.transpose(-2, -1) * E2 ** -0.5        \n",
    "        \n",
    "        wei = wei.masked_fill(\n",
    "                      self.tril[:T, :T] == 0, \n",
    "                      float('-inf')\n",
    "        )   \n",
    "        \n",
    "        ## (B, T, T)\n",
    "        wei = F.softmax( wei, dim= -1 )         ## (B, T, T)\n",
    "        wei = self.dropout(   wei   )\n",
    "        \n",
    "        ## perform weighted aggregation of values\n",
    "        \n",
    "        v   = self.value(  x  )   ## x = (B, 40, E)\n",
    "        out = wei @ v             ## (B, T, T) @ (B, T, 64) -> (B, T, 64)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embd, dropout):         ## 512\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),      ## [512, 4*512]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),      ## [4*512, 512]\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, n_head, head_size, block_size, n_embd, dropout):    ## (8, 64)\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(  [ Head(head_size, block_size, n_embd, dropout) for _ in range(n_head) ] )\n",
    "        self.proj  = nn.Linear(n_embd, n_embd)   ## 512, 512\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.cat(   [ h(x) for h in self.heads ], dim = -1   )\n",
    "        out = self.proj(  out   )\n",
    "        out = self.dropout(   out   )\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_head, block_size, n_embd, dropout):     ## (512, 8)\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head        ## 64\n",
    "        self.sa   = MultiHeadAttention(n_head, head_size, block_size, n_embd, dropout)\n",
    "        self.ffwd = FeedForward( n_embd, dropout)    ## 512\n",
    "        self.ln1  = nn.LayerNorm(n_embd)\n",
    "        self.ln2  = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(     self.ln1(x)      )\n",
    "        x = x + self.ffwd(   self.ln2(x)      )\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self,vocab_size, n_embd, block_size, n_layer, n_head, dropout):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)   ## [65, 512]\n",
    "        self.pos_emb_table = nn.Embedding(block_size, n_embd)     ## [block, 512]\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "                *[ Block(n_head, block_size, n_embd, dropout) for _ in range(n_layer) ]\n",
    "        )\n",
    "        \n",
    "        self.ln_f    = nn.LayerNorm(  n_embd    )        \n",
    "        self.lm_ffw_head = nn.Linear(n_embd, vocab_size)  ## [512, 65] # FFW Layer\n",
    "        self.block_size = block_size\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape     ## (Batch, 40)\n",
    "        ## ids and targets are both (B, T) tensors of integers\n",
    "\n",
    "        \n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.pos_emb_table(torch.arange(T, device=device))  \n",
    "        \n",
    "        x = tok_emb + pos_emb    ## [B, T, E] or [64, 40, 512]\n",
    "\n",
    "        ## This is the architecture\n",
    "        x = self.blocks(  x  )   ## (B, T, E)        \n",
    "        x = self.ln_f(    x  )   ## (B, T, E)   ## norm\n",
    "        logits = self.lm_ffw_head(x)         ## [B, 40, 65] \n",
    "        \n",
    "        # if targets is None:\n",
    "        #     loss = None\n",
    "        # else:\n",
    "        #     B, T, E  = logits.shape\n",
    "        #     logits  = logits.view( B*T, E)\n",
    "        #     targets = targets.view(B*T)\n",
    "        #     loss    = F.cross_entropy(logits, targets)\n",
    "        return logits#, loss\n",
    "        \n",
    "    def generate(self, idx, max_new_tokens):    ## idx is (B, T)\n",
    "        for _ in range(max_new_tokens):\n",
    "            ## crop idx to the last block_size tokens\n",
    "            # idx_cond, _loss\n",
    "            idx_cond = idx[:, -self.block_size:]\n",
    "            logits = self(idx_cond)    ## ## get preds\n",
    "            logits = logits[:, -1, :]    ## focus on last one (B, E)\n",
    "            probs = F.softmax(logits, dim= -1)    ## (B, E) get probs\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)     ## (B, 1) selected\n",
    "            idx = torch.cat(  (idx, idx_next), dim=1  )   ## (B, T+1) append sample to running sequence\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, stride=128, window=None, files=None, max_length=1024):\n",
    "        self.files = files\n",
    "\n",
    "        dataset = []\n",
    "        df = pd.read_csv('exchange_rate.txt', header=None)\n",
    "        df = df.dropna() # i think axis=1 drops columns\n",
    "        # drop any columns with str\n",
    "        df = df.drop(df.select_dtypes(['object']), axis=1)\n",
    "\n",
    "        df = df.iloc[:, 0]\n",
    "\n",
    "        norm_df = (df - df.min()) * (50_257-2) / ( df.max() - df.min() )\n",
    "        n_cols = 1#norm_df.shape[1]\n",
    "\n",
    "        tokens = norm_df.values.flatten().astype(int)\n",
    "        \n",
    "        # Create sequences with sliding window\n",
    "        samples = 0\n",
    "        for i in range(0, len(tokens) - max_length, stride):\n",
    "            sequence = tokens[i:i + max_length]\n",
    "            if len(sequence) == max_length:\n",
    "                input_sequence = np.array(sequence[:-n_cols])#, dtype=np.int64) # dont include the last token\n",
    "                target_sequence = np.array(sequence[n_cols:])#, dtype=np.int64) # dont include the first token\n",
    "\n",
    "                dataset.append({\n",
    "                    'input_ids': input_sequence,\n",
    "                    'labels': target_sequence\n",
    "                })\n",
    "            samples += 1\n",
    "            if samples > 512: # 1024\n",
    "                print('max samples from file')\n",
    "                break\n",
    "        print('samples:', samples)\n",
    "\n",
    "        self.data = dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        # print(item['input_ids'].shape, item['labels'].shape, torch.ones_like(torch.tensor(item['input_ids'])).shape)\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(item['input_ids']).to(device),\n",
    "            'labels': torch.tensor(item['labels']).to(device),\n",
    "            'attention_mask': torch.ones_like(torch.tensor(item['input_ids'])).to(device)\n",
    "        }\n",
    "    \n",
    "    def min(self):\n",
    "        if len(self.files) == 1:\n",
    "            return self.min_val\n",
    "        else:\n",
    "            raise Exception(\"Multiple files, use min_val from each file\")\n",
    "    \n",
    "    def max(self):\n",
    "        if len(self.files) == 1:\n",
    "            return self.max_val\n",
    "        else:\n",
    "            raise Exception(\"Multiple files, use max_val from each file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## every id for a given token is embedded to vector of this size\n",
    "n_embd            = 768        # GPT-2\n",
    "n_head            = 4#12         # GPT-2\n",
    "n_layer           = 4#12         # GPT-2\n",
    "dropout           = 0.2#0.1        # GPT-2\n",
    "\n",
    "learning_rate     = 2.5e-4     # GPT-2\n",
    "vocab_size        = 50_257     # GPT-2 50_257\n",
    "block_size        = 512 # 1024       # GPT-2 (context) ## N tokens in sequence\n",
    "\n",
    "batch_size        = 4\n",
    "# max_iters         = 512\n",
    "eval_interval     = 512\n",
    "# eval_iters        = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(\n",
    "                   vocab_size=vocab_size, \n",
    "                    n_embd=n_embd,\n",
    "                    block_size=block_size,\n",
    "                    n_layer=n_layer,\n",
    "                    n_head=n_head,\n",
    "                    dropout=dropout\n",
    "                ).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging Face Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "from transformers.modeling_outputs import CausalLMOutput\n",
    "\n",
    "class GPTConfig(PretrainedConfig):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block_size=1024,\n",
    "        vocab_size=50_257,\n",
    "        n_embd=768,\n",
    "        n_head=8,\n",
    "        n_layer=8,\n",
    "        dropout=0.1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_embd = n_embd\n",
    "        self.n_head = n_head\n",
    "        self.n_layer = n_layer\n",
    "        self.dropout = dropout\n",
    "\n",
    "class GPTModelForTrainer(PreTrainedModel):\n",
    "    config_class = GPTConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        # keep model inside because we cant pass it in\n",
    "        self.model = GPTModel(\n",
    "                    vocab_size=vocab_size,\n",
    "                    n_embd=n_embd,\n",
    "                    block_size=block_size,\n",
    "                    n_layer=n_layer,\n",
    "                    n_head=n_head,\n",
    "                    dropout=dropout\n",
    "                )\n",
    "        \n",
    "    def forward(self, input_ids, labels=None, **kwargs):\n",
    "        logits = self.model(input_ids)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            shift_logits = logits[..., :-1, :].contiguous() # TODO these are decimal\n",
    "            shift_labels = labels[..., 1:].contiguous().long()\n",
    "\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)),\n",
    "                          shift_labels.view(-1))\n",
    "            \n",
    "        return CausalLMOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: 56\n"
     ]
    }
   ],
   "source": [
    "train_dataset = GPTDataset(max_length=block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12600' max='12600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12600/12600 19:02, Epoch 900/900]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>2.362000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1024</td>\n",
       "      <td>0.009400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1536</td>\n",
       "      <td>0.003500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2048</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3072</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3584</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4096</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4608</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5120</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5632</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6144</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6656</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7168</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7680</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8192</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8704</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9216</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9728</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10240</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10752</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11264</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11776</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12288</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12600, training_loss=0.09687749598796169, metrics={'train_runtime': 1143.0884, 'train_samples_per_second': 44.091, 'train_steps_per_second': 11.023, 'total_flos': 1.03519462085424e+16, 'train_loss': 0.09687749598796169, 'epoch': 900.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt_model\",\n",
    "    num_train_epochs=900,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    # per_device_eval_batch_size=batch_size,\n",
    "    # eval_steps=eval_interval,\n",
    "    save_steps=eval_interval,\n",
    "    save_total_limit=2,\n",
    "    warmup_steps=100,\n",
    "    learning_rate=learning_rate,\n",
    "    # fp16=True,  # if you want to use mixed precision training\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=eval_interval,\n",
    "    dataloader_pin_memory=False,\n",
    ")\n",
    "\n",
    "# Wrap the model\n",
    "config = GPTConfig(\n",
    "    block_size=block_size,\n",
    "    vocab_size=vocab_size,\n",
    "    n_embd=n_embd,\n",
    "    n_head=n_head,\n",
    "    n_layer=n_layer,\n",
    "    dropout=dropout,\n",
    ")\n",
    "\n",
    "model_for_trainer = GPTModelForTrainer(config)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_for_trainer,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    # eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt_model/checkpoint-12600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModelForTrainer(\n",
       "  (model): GPTModel(\n",
       "    (token_embedding_table): Embedding(50257, 768)\n",
       "    (pos_emb_table): Embedding(512, 768)\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-3): 4 x Head(\n",
       "              (key): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-3): 4 x Head(\n",
       "              (key): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-3): 4 x Head(\n",
       "              (key): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-3): 4 x Head(\n",
       "              (key): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (lm_ffw_head): Linear(in_features=768, out_features=50257, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved weights\n",
    "# Replace 'checkpoint-XXX' with the specific checkpoint you want to load\n",
    "checkpoint_path = \"./gpt_model/checkpoint-512\"  # or whatever your output_dir/checkpoint-XXX is\n",
    "\n",
    "import os\n",
    "checkpoint_path = max([f\"gpt_model/{f}\" for f in os.listdir('gpt_model') if os.path.isdir(f\"gpt_model/{f}\")], key=os.path.getmtime)\n",
    "\n",
    "print(checkpoint_path)\n",
    "model_for_trainer = GPTModelForTrainer.from_pretrained(checkpoint_path)\n",
    "\n",
    "# Put model in evaluation mode if you're going to use it for inference\n",
    "model_for_trainer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: 52\n",
      "start\n",
      "real tensor([24225, 24622, 24566, 24476, 24614, 24777, 24971, 25207, 24842, 25028,\n",
      "        25223, 25174, 25329, 23681, 22634, 22318, 22496, 22740, 22943, 23145,\n",
      "        23283, 23551, 22902, 22983, 22253, 22009, 21587, 21814, 21814, 21295,\n",
      "        21644, 22188], device='cuda:0', dtype=torch.int32)\n",
      "pred tensor([24225, 24622, 24566, 24476, 24614, 24777, 24971, 25207, 24842, 25028,\n",
      "        25223, 25174, 25329, 23681, 22634, 22318, 22496, 22740, 22943, 23145,\n",
      "        23283, 23551, 22902, 22983, 22253, 22009, 21587, 21814, 21814, 21295,\n",
      "        21644, 22188], device='cuda:0')\n",
      "middle (1020:1050)\n",
      "real tensor([18357, 18422, 18357, 18479, 18503, 17968, 17505, 17708, 17854, 17951,\n",
      "        18601, 19534, 19429, 19493, 19331, 19453, 19453, 19006, 18804, 18901,\n",
      "        18682, 19088, 18950], device='cuda:0', dtype=torch.int32)\n",
      "pred tensor([18357, 18422, 18357, 18479, 18503, 17968, 17505, 17708, 17854, 17951,\n",
      "        18601, 19534, 19429, 19493, 19331, 19453, 19453, 19006, 18804, 18901,\n",
      "        18682, 19088, 35790], device='cuda:0')\n",
      "end\n",
      "real tensor([18739, 18317, 18414, 19071, 19047, 18641, 18601, 18617, 18300, 18357,\n",
      "        18422, 18357, 18479, 18503, 17968, 17505, 17708, 17854, 17951, 18601,\n",
      "        19534, 19429, 19493, 19331, 19453, 19453, 19006, 18804, 18901, 18682,\n",
      "        19088, 18950], device='cuda:0', dtype=torch.int32)\n",
      "pred tensor([18739, 18317, 18414, 19071, 19047, 18641, 18601, 18617, 18300, 18357,\n",
      "        18422, 18357, 18479, 18503, 17968, 17505, 17708, 17854, 17951, 18601,\n",
      "        19534, 19429, 19493, 19331, 19453, 19453, 19006, 18804, 18901, 18682,\n",
      "        19088, 35790], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 70.55it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real: shape: torch.Size([100]), goal val: 18950.0\n",
      "min: 21490.0, max: 21490.0, mean: 21490.0, std: 0.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_dataset = GPTDataset(files=['exchange_rate.txt'], max_length=1024)\n",
    "\n",
    "# Generate text\n",
    "output = model.generate(\n",
    "    test_dataset[0]['input_ids'].unsqueeze(0),\n",
    "    # max_length=512,\n",
    "    max_new_tokens=1,\n",
    "    # temperature=0.7,\n",
    "    # num_return_sequences=1,\n",
    "    # pad_token_id=vocab_size - 1,\n",
    "    # do_sample=True\n",
    ")\n",
    "\n",
    "torch.set_printoptions(profile='full')\n",
    "print('start')\n",
    "print('real',test_dataset[0]['labels'][:32])\n",
    "print('pred',output[0][1:33])\n",
    "print('middle (1020:1050)')\n",
    "print('real',test_dataset[0]['labels'][1000:1050])\n",
    "print('pred',output[0][1001:1051])\n",
    "print('end')\n",
    "print('real',test_dataset[0]['labels'][-32:])\n",
    "print('pred',output[0][-32:])\n",
    "torch.set_printoptions(profile='default')\n",
    "\n",
    "# create scatter plot\n",
    "n = 100\n",
    "m = 1\n",
    "\n",
    "# not sure how to line up the real and pred when using different size. so i will just change dataset size\n",
    "real = torch.full_like(torch.zeros(n), test_dataset[0]['labels'][-1])\n",
    "pred = torch.zeros(n)\n",
    "\n",
    "pbar = tqdm(range(0, n, m), total=n)\n",
    "for i in pbar:\n",
    "    output = model.generate(\n",
    "        test_dataset[0]['input_ids'][:512].unsqueeze(0),\n",
    "        max_new_tokens=1,\n",
    "    )\n",
    "\n",
    "    for j in range(m): # -1\n",
    "        pred[i+j] = output[j][512-1].cpu() # have to do this to get the value\n",
    "    pbar.update(m)\n",
    "\n",
    "# create scatter plot\n",
    "plt.scatter(range(n), real, label='real')\n",
    "plt.scatter(range(n), pred, label='pred')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame({'Predictions': pred})\n",
    "\n",
    "# Create the violin plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.violinplot(y='Predictions', data=df)\n",
    "plt.title(f\"Distribution of  Predictions\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"real: shape: {real.shape}, goal val: {real[0]}\")\n",
    "print(f\"min: {min(pred)}, max: {max(pred)}, mean: {torch.mean(pred)}, std: {torch.std(pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\joeya\\anaconda3\\envs\\py38-its520-project\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\joeya\\anaconda3\\envs\\py38-its520-project\\lib\\site-packages (from seaborn) (1.24.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\joeya\\anaconda3\\envs\\py38-its520-project\\lib\\site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\joeya\\anaconda3\\envs\\py38-its520-project\\lib\\site-packages (from seaborn) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\joeya\\anaconda3\\envs\\py38-its520-project\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\joeya\\anaconda3\\envs\\py38-its520-project\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\joeya\\anaconda3\\envs\\py38-its520-project\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\joeya\\anaconda3\\envs\\py38-its520-project\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\joeya\\anaconda3\\envs\\py38-its520-project\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\joeya\\anaconda3\\envs\\py38-its520-project\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\joeya\\anaconda3\\envs\\py38-its520-project\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\joeya\\anaconda3\\envs\\py38-its520-project\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\joeya\\anaconda3\\envs\\py38-its520-project\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\joeya\\anaconda3\\envs\\py38-its520-project\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\joeya\\anaconda3\\envs\\py38-its520-project\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\joeya\\anaconda3\\envs\\py38-its520-project\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\joeya\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
