{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<module 'torch.backends.mps' from 'C:\\\\Users\\\\joeya\\\\anaconda3\\\\envs\\\\py38-ITS520-Project\\\\lib\\\\site-packages\\\\torch\\\\backends\\\\mps\\\\__init__.py'>\n",
      "devices: 1\n",
      "device:  NVIDIA GeForce RTX 3080\n",
      "device0: _CudaDeviceProperties(name='NVIDIA GeForce RTX 3080', major=8, minor=6, total_memory=10239MB, multi_processor_count=68)\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.mps)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    # get number of cuda devices\n",
    "    print(f\"devices: {torch.cuda.device_count()}\")\n",
    "    print(f\"device:  {torch.cuda.get_device_name()}\")\n",
    "    print(f\"device0: {torch.cuda.get_device_properties(0)}\")\n",
    "    print(f\"{torch.cuda.memory_summary()}\")\n",
    "elif torch.backends.mps is not None:\n",
    "    device = torch.device('mps')\n",
    "    print(f\"{torch.mps.current_allocated_memory()}\")\n",
    "    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    # print a warning that cpu is being used\n",
    "    print(\"Warning: Running on CPU. This will be slow.\")\n",
    "print(f\"{device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "\n",
    "    def __init__(self, head_size, block_size, n_embd, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.key   = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
    "\n",
    "        tril_def = torch.tril( torch.ones(block_size, block_size) )  ## [40, 40]\n",
    "        \n",
    "        self.register_buffer(\n",
    "                  'tril', \n",
    "                  tril_def\n",
    "               )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        B, T, E = x.shape   ## [batch_size, 40, 512]\n",
    "        \n",
    "        k = self.key(   x )            ## k = (B, T, 64)\n",
    "        q = self.query( x )            ## q = (B, T, 64)\n",
    "\n",
    "        E2 = 64     ## I think this is 64 and not 512\n",
    "        ## (B, T, E) @ (B, E, T)  -> (B, T, T)\n",
    "        wei = q @ k.transpose(-2, -1) * E2 ** -0.5        \n",
    "        \n",
    "        wei = wei.masked_fill(\n",
    "                      self.tril[:T, :T] == 0, \n",
    "                      float('-inf')\n",
    "        )   \n",
    "        \n",
    "        ## (B, T, T)\n",
    "        wei = F.softmax( wei, dim= -1 )         ## (B, T, T)\n",
    "        wei = self.dropout(   wei   )\n",
    "        \n",
    "        ## perform weighted aggregation of values\n",
    "        \n",
    "        v   = self.value(  x  )   ## x = (B, 40, E)\n",
    "        out = wei @ v             ## (B, T, T) @ (B, T, 64) -> (B, T, 64)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embd, dropout):         ## 512\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),      ## [512, 4*512]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),      ## [4*512, 512]\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, n_head, head_size, block_size, n_embd, dropout):    ## (8, 64)\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(  [ Head(head_size, block_size, n_embd, dropout) for _ in range(n_head) ] )\n",
    "        self.proj  = nn.Linear(n_embd, n_embd)   ## 512, 512\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.cat(   [ h(x) for h in self.heads ], dim = -1   )\n",
    "        out = self.proj(  out   )\n",
    "        out = self.dropout(   out   )\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_head, block_size, n_embd, dropout):     ## (512, 8)\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head        ## 64\n",
    "        self.sa   = MultiHeadAttention(n_head, head_size, block_size, n_embd, dropout)\n",
    "        self.ffwd = FeedForward( n_embd, dropout)    ## 512\n",
    "        self.ln1  = nn.LayerNorm(n_embd)\n",
    "        self.ln2  = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(     self.ln1(x)      )\n",
    "        x = x + self.ffwd(   self.ln2(x)      )\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self,vocab_size, n_embd, block_size, n_layer, n_head, dropout):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)   ## [65, 512]\n",
    "        self.pos_emb_table = nn.Embedding(block_size, n_embd)     ## [block, 512]\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "                *[ Block(n_head, block_size, n_embd, dropout) for _ in range(n_layer) ]\n",
    "        )\n",
    "        \n",
    "        self.ln_f    = nn.LayerNorm(  n_embd    )        \n",
    "        self.lm_ffw_head = nn.Linear(n_embd, vocab_size)  ## [512, 65] # FFW Layer\n",
    "        self.block_size = block_size\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape     ## (Batch, 40)\n",
    "        ## ids and targets are both (B, T) tensors of integers\n",
    "        \n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.pos_emb_table(torch.arange(T, device=device))  \n",
    "        \n",
    "        x = tok_emb + pos_emb    ## [B, T, E] or [64, 40, 512]\n",
    "\n",
    "        ## This is the architecture\n",
    "        x = self.blocks(  x  )   ## (B, T, E)        \n",
    "        x = self.ln_f(    x  )   ## (B, T, E)   ## norm\n",
    "        logits = self.lm_ffw_head(x)         ## [B, 40, 65] \n",
    "        \n",
    "        # if targets is None:\n",
    "        #     loss = None\n",
    "        # else:\n",
    "        #     B, T, E  = logits.shape\n",
    "        #     logits  = logits.view( B*T, E)\n",
    "        #     targets = targets.view(B*T)\n",
    "        #     loss    = F.cross_entropy(logits, targets)\n",
    "        return logits#, loss\n",
    "        \n",
    "    def generate(self, idx, max_new_tokens):    ## idx is (B, T)\n",
    "        for _ in range(max_new_tokens):\n",
    "            ## crop idx to the last block_size tokens\n",
    "            # idx_cond, _loss\n",
    "            idx_cond = idx[:, -self.block_size:]\n",
    "            logits = self(idx_cond)    ## ## get preds\n",
    "            logits = logits[:, -1, :]    ## focus on last one (B, E)\n",
    "            probs = F.softmax(logits, dim= -1)    ## (B, E) get probs\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)     ## (B, 1) selected\n",
    "            idx = torch.cat(  (idx, idx_next), dim=1  )   ## (B, T+1) append sample to running sequence\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, stride=128, window=None, files=None):\n",
    "        self.files = files\n",
    "\n",
    "        max_length = 1024\n",
    "        if window is not None:\n",
    "            max_length = window\n",
    "\n",
    "        dataset = []\n",
    "        df = pd.read_csv('000_arithmetic.csv', header=None)\n",
    "        df = df.dropna() # i think axis=1 drops columns\n",
    "        # drop any columns with str\n",
    "        df = df.drop(df.select_dtypes(['object']), axis=1)\n",
    "\n",
    "        df = df.iloc[:, 0]\n",
    "\n",
    "        norm_df = (df - df.min()) * (50_257-2) / ( df.max() - df.min() )\n",
    "        n_cols = 1#norm_df.shape[1]\n",
    "\n",
    "        tokens = norm_df.values.flatten().astype(int)\n",
    "        \n",
    "        # Create sequences with sliding window\n",
    "        samples = 0\n",
    "        for i in range(0, len(tokens) - max_length, stride):\n",
    "            sequence = tokens[i:i + max_length]\n",
    "            if len(sequence) == max_length:\n",
    "                input_sequence = np.array(sequence[:-n_cols])#, dtype=np.int64) # dont include the last token\n",
    "                target_sequence = np.array(sequence[n_cols:])#, dtype=np.int64) # dont include the first token\n",
    "\n",
    "                dataset.append({\n",
    "                    'input_ids': input_sequence,\n",
    "                    'labels': target_sequence\n",
    "                })\n",
    "            samples += 1\n",
    "            if samples > 512: # 1024\n",
    "                print('max samples from file')\n",
    "                break\n",
    "        print('samples:', samples)\n",
    "\n",
    "        self.data = dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        # print(item['input_ids'].shape, item['labels'].shape, torch.ones_like(torch.tensor(item['input_ids'])).shape)\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(item['input_ids']).to(device),\n",
    "            'labels': torch.tensor(item['labels']).to(device),\n",
    "            'attention_mask': torch.ones_like(torch.tensor(item['input_ids'])).to(device)\n",
    "        }\n",
    "    \n",
    "    def min(self):\n",
    "        if len(self.files) == 1:\n",
    "            return self.min_val\n",
    "        else:\n",
    "            raise Exception(\"Multiple files, use min_val from each file\")\n",
    "    \n",
    "    def max(self):\n",
    "        if len(self.files) == 1:\n",
    "            return self.max_val\n",
    "        else:\n",
    "            raise Exception(\"Multiple files, use max_val from each file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## every id for a given token is embedded to vector of this size\n",
    "n_embd            = 768        # GPT-2\n",
    "n_head            = 4#12         # GPT-2\n",
    "n_layer           = 8#12         # GPT-2\n",
    "dropout           = 0.1        # GPT-2\n",
    "\n",
    "learning_rate     = 2.5e-4     # GPT-2\n",
    "vocab_size        = 50_257     # GPT-2 50_257\n",
    "block_size        = 512       # GPT-2 (context) ## N tokens in sequence\n",
    "\n",
    "batch_size        = 2\n",
    "# max_iters         = 512\n",
    "eval_interval     = 512\n",
    "# eval_iters        = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging Face Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "from transformers.modeling_outputs import CausalLMOutput\n",
    "\n",
    "class GPTConfig(PretrainedConfig):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block_size=1024,\n",
    "        vocab_size=50_257,\n",
    "        n_embd=768,\n",
    "        n_head=8,\n",
    "        n_layer=8,\n",
    "        dropout=0.1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_embd = n_embd\n",
    "        self.n_head = n_head\n",
    "        self.n_layer = n_layer\n",
    "        self.dropout = dropout\n",
    "\n",
    "class GPTModelForTrainer(PreTrainedModel):\n",
    "    config_class = GPTConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_embd = n_embd\n",
    "        self.block_size = block_size\n",
    "        self.n_layer = n_layer\n",
    "        self.n_head = n_head\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # keep model inside because we cant pass it in\n",
    "        self.model = GPTModel(\n",
    "                    vocab_size=self.vocab_size,\n",
    "                    n_embd=self.n_embd,\n",
    "                    block_size=self.block_size,\n",
    "                    n_layer=self.n_layer,\n",
    "                    n_head=self.n_head,\n",
    "                    dropout=self.dropout\n",
    "                )\n",
    "        \n",
    "    def forward(self, input_ids, labels=None, **kwargs):\n",
    "        logits = self.model(input_ids)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            shift_logits = logits[..., :, :].contiguous()\n",
    "            shift_labels = labels[..., :].contiguous().long()\n",
    "\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)),\n",
    "                          shift_labels.view(-1))\n",
    "            \n",
    "        return CausalLMOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "        )\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        idx: (B, T) array of indices in the current context\n",
    "        max_new_tokens: number of tokens to generate\n",
    "        temperature: control randomness (1.0 = neutral, < 1.0 = more deterministic, > 1.0 = more random)\n",
    "        top_k: limit sampling to top k most likely tokens (None = no limit)\n",
    "        \"\"\"\n",
    "        # Make sure model is in eval mode\n",
    "        self.eval()\n",
    "        \n",
    "        # Loop until we generate all requested tokens\n",
    "        for _ in range(max_new_tokens):\n",
    "            # If context length exceeds block_size, crop it\n",
    "            idx_cond = idx if idx.size(1) <= self.block_size else idx[:, -self.block_size:]\n",
    "            \n",
    "            # Get predictions\n",
    "            logits = self(idx_cond)['logits']\n",
    "            \n",
    "            # Focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            \n",
    "            # Apply temperature\n",
    "            logits = logits / temperature\n",
    "            \n",
    "            # Optionally crop logits to only the top k options\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            \n",
    "            # Apply softmax to convert logits to probabilities\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            \n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            \n",
    "            # Append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        \n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: 76\n"
     ]
    }
   ],
   "source": [
    "train_dataset = GPTDataset(window=block_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1140' max='1140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1140/1140 01:56, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>2.776800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1024</td>\n",
       "      <td>0.013200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1140, training_loss=1.2540077695721075, metrics={'train_runtime': 116.4474, 'train_samples_per_second': 19.58, 'train_steps_per_second': 9.79, 'total_flos': 666428414052240.0, 'train_loss': 1.2540077695721075, 'epoch': 30.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "output_dir = Path('models') / time.strftime(\"%y-%m-%d_%H\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='gpt_model',\n",
    "    num_train_epochs=30,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    # per_device_eval_batch_size=batch_size,\n",
    "    # eval_steps=eval_interval,\n",
    "    save_steps=eval_interval,\n",
    "    save_total_limit=2,\n",
    "    warmup_steps=100,\n",
    "    learning_rate=learning_rate,\n",
    "    # fp16=True,  # if you want to use mixed precision training\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=eval_interval,\n",
    "    dataloader_pin_memory=False,\n",
    ")\n",
    "\n",
    "# Wrap the model\n",
    "config = GPTConfig(\n",
    "    block_size=block_size,\n",
    "    vocab_size=vocab_size,\n",
    "    n_embd=n_embd,\n",
    "    n_head=n_head,\n",
    "    n_layer=n_layer,\n",
    "    dropout=dropout,\n",
    ")\n",
    "\n",
    "model_for_trainer = GPTModelForTrainer(config)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_for_trainer,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    # eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt_model/checkpoint-1140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModelForTrainer(\n",
       "  (model): GPTModel(\n",
       "    (token_embedding_table): Embedding(50257, 768)\n",
       "    (pos_emb_table): Embedding(512, 768)\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-3): 4 x Head(\n",
       "              (key): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-3): 4 x Head(\n",
       "              (key): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-3): 4 x Head(\n",
       "              (key): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-3): 4 x Head(\n",
       "              (key): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-3): 4 x Head(\n",
       "              (key): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-3): 4 x Head(\n",
       "              (key): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-3): 4 x Head(\n",
       "              (key): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-3): 4 x Head(\n",
       "              (key): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (query): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=192, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (lm_ffw_head): Linear(in_features=768, out_features=50257, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved weights\n",
    "# Replace 'checkpoint-XXX' with the specific checkpoint you want to load\n",
    "checkpoint_path = \"./gpt_model/checkpoint-512\"  # or whatever your output_dir/checkpoint-XXX is\n",
    "\n",
    "import os\n",
    "checkpoint_path = max([f\"gpt_model/{f}\" for f in os.listdir('gpt_model') if os.path.isdir(f\"gpt_model/{f}\")], key=os.path.getmtime)\n",
    "\n",
    "print(checkpoint_path)\n",
    "model_for_trainer = GPTModelForTrainer.from_pretrained(checkpoint_path)\n",
    "\n",
    "# Put model in evaluation mode if you're going to use it for inference\n",
    "model_for_trainer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: 76\n",
      "start\n",
      "real tensor([  4,   9,  14,  19,  24,  29,  34,  39,  44,  49,  53,  58,  63,  68,\n",
      "         73,  78,  83,  88,  93,  98, 103, 107, 112, 117, 122, 127, 132, 137,\n",
      "        142, 147, 152, 157], dtype=torch.int32)\n",
      "pred tensor([  4,   9,  14,  19,  24,  29,  34,  39,  44,  49,  53,  58,  63,  68,\n",
      "         73,  78,  83,  88,  93,  98, 103, 107, 112, 117, 122, 127, 132, 137,\n",
      "        142, 147, 152, 157])\n",
      "middle (1020:1050)\n",
      "real tensor([], dtype=torch.int32)\n",
      "pred tensor([], dtype=torch.int64)\n",
      "end\n",
      "real tensor([2356, 2361, 2365, 2370, 2375, 2380, 2385, 2390, 2395, 2400, 2405, 2410,\n",
      "        2415, 2419, 2424, 2429, 2434, 2439, 2444, 2449, 2454, 2459, 2464, 2469,\n",
      "        2473, 2478, 2483, 2488, 2493, 2498, 2503, 2508], dtype=torch.int32)\n",
      "pred tensor([2356, 2361, 2365, 2370, 2375, 2380, 2385, 2390, 2395, 2400, 2405, 2410,\n",
      "        2415, 2419, 2424, 2429, 2434, 2439, 2444, 2449, 2454, 2459, 2464, 2469,\n",
      "        2473, 2478, 2483, 2488, 2493, 2498, 2503, 2508])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:31<00:00,  3.17it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsAAAAH9CAYAAAAUI8oBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0q0lEQVR4nO3de1hU5aLH8d8gMqIyoNmIBCFHyjTNtMzQUlMTFSvb7dNW08RrJmZoF7Wyi+4kNa/dbJ+epJsny51a3tkCmqVlbsmtpanbC6agJ5NRNBNY5w8f124EFcZBqPf7eZ55Hmatd9Z618DZ59tyzRqHZVmWAAAAAEMEVPQEAAAAgMuJAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGUGGef/55ORyOy7Kv9u3bq3379vbzzMxMORwOzZ8//7LsPzExUfXr178s+/LV8ePHNWjQIIWHh8vhcCg5Obmip1Qme/bskcPhUGpqqr3M339jZ/9uMjMz/bZNAJcfAQzAL1JTU+VwOOxHtWrVFBERofj4eM2aNUvHjh3zy34OHDig559/XllZWX7Znj9V5rmVxsSJE5WamqqHH35Y7733nvr27Vum1ycmJnr9DbhcLjVr1kxTp07VqVOnymnW5eP111/3CmkAfyyBFT0BAH8s48ePV0xMjE6fPq2cnBxlZmYqOTlZ06ZN06effqobbrjBHvvMM89ozJgxZdr+gQMH9MILL6h+/fq68cYbS/26lStXlmk/vrjQ3P7nf/5HRUVF5T6HS5Genq5bb71Vzz33nM/bcDqdeuuttyRJR48e1d///nc9/vjj2rBhgz788EN/TbXUfPkbk84EcJ06dZSYmOi1vG3btjp58qSCgoL8NEMAFYEABuBXXbt21c0332w/Hzt2rNLT09W9e3fdfffd+v777xUcHCxJCgwMVGBg+f7P0IkTJ1S9evUKD5aqVatW6P5L49ChQ2rcuPElbSMwMFB9+vSxnw8bNkytWrXSvHnzNG3aNEVERBR7jWVZ+uWXX+y/C3/y999YQECAqlWr5rftAagYXAIBoNx16NBB48aN0969e/X+++/by0u6PjMtLU233XabwsLCVLNmTTVs2FBPPfWUpDPXX7Zs2VKS1L9/f/uf2s/+U3X79u3VpEkTbdy4UW3btlX16tXt1557DfBZhYWFeuqppxQeHq4aNWro7rvvVnZ2tteY+vXrFzsTeO42Lza3kq4Bzs/P12OPPaaoqCg5nU41bNhQL7/8sizL8hrncDg0fPhwLVy4UE2aNJHT6dT111+v5cuXl/yGn+PQoUMaOHCg6tatq2rVqqlZs2Z655137PVnr2vdvXu3lixZYs99z549pdr+hQQEBNjv0dnt1a9fX927d9eKFSt08803Kzg4WG+++aakM2eNk5OT7fckNjZWkyZNKnb2/OjRo0pMTFRoaKjCwsLUr18/HT16tNj+z3cN8Pvvv69bbrlF1atXV61atdS2bVv7Xwnq16+vrVu3avXq1fZ78dvfc0nXAH/88ce66aabFBwcrDp16qhPnz768ccfvcYkJiaqZs2a+vHHH9WjRw/VrFlTV155pR5//HEVFhZ6jf3www910003KSQkRC6XS02bNtXMmTNL85YDKAXOAAO4LPr27aunnnpKK1eu1ODBg0scs3XrVnXv3l033HCDxo8fL6fTqZ07d+qLL76QJDVq1Ejjx4/Xs88+qyFDhuj222+XJLVu3drexk8//aSuXbuqZ8+e6tOnj+rWrXvBeb344otyOBwaPXq0Dh06pBkzZqhTp07Kysoq0xnJ0szttyzL0t13362MjAwNHDhQN954o1asWKEnnnhCP/74o6ZPn+41fu3atfrkk080bNgwhYSEaNasWbrvvvu0b98+XXHFFeed18mTJ9W+fXvt3LlTw4cPV0xMjD7++GMlJibq6NGjevTRR9WoUSO99957GjlypCIjI/XYY49Jkq688spSH/+F7Nq1S5K85rl9+3b16tVLDz30kAYPHqyGDRvqxIkTateunX788Uc99NBDuvrqq/Xll19q7NixOnjwoGbMmGG/d/fcc4/Wrl2roUOHqlGjRlqwYIH69etXqvm88MILev7559W6dWuNHz9eQUFB+uqrr5Senq7OnTtrxowZeuSRR1SzZk09/fTTknTBv6PU1FT1799fLVu2VEpKinJzczVz5kx98cUX2rRpk8LCwuyxhYWFio+PV6tWrfTyyy/rH//4h6ZOnaoGDRro4YcflnTmPwJ79eqljh07atKkSZKk77//Xl988YUeffTRUr/vAC7AAgA/mDNnjiXJ2rBhw3nHhIaGWs2bN7efP/fcc9Zv/2do+vTpliTr8OHD593Ghg0bLEnWnDlziq1r166dJcmaPXt2ievatWtnP8/IyLAkWVdddZXl8Xjs5R999JElyZo5c6a9LDo62urXr99Ft3mhufXr18+Kjo62ny9cuNCSZP31r3/1GvfnP//Zcjgc1s6dO+1lkqygoCCvZd9++60lyXrllVeK7eu3ZsyYYUmy3n//fXvZr7/+asXFxVk1a9b0Ovbo6GgrISHhgtu7kH79+lk1atSwDh8+bB0+fNjauXOnNXHiRMvhcFg33HCD134kWcuXL/d6/YQJE6waNWpYP/zwg9fyMWPGWFWqVLH27dtnWdZ/3rvJkyfbYwoKCqzbb7+92Pt/7t/Yjh07rICAAOvee++1CgsLvfZTVFRk/3z99dd7/W7POvt3k5GRYVnWmffS7XZbTZo0sU6ePGmPW7x4sSXJevbZZ73eH0nW+PHjvbbZvHlz66abbrKfP/roo5bL5bIKCgqK7R+Af3AJBIDLpmbNmhe8G8TZM2WLFi3y+QNjTqdT/fv3L/X4Bx98UCEhIfbzP//5z6pXr56WLl3q0/5La+nSpapSpYpGjBjhtfyxxx6TZVlatmyZ1/JOnTqpQYMG9vMbbrhBLpdL//73vy+6n/DwcPXq1cteVrVqVY0YMULHjx/X6tWr/XA0/5Gfn68rr7xSV155pWJjY/XUU08pLi5OCxYs8BoXExOj+Ph4r2Uff/yxbr/9dtWqVUv/93//Zz86deqkwsJCrVmzxj6mwMBA+4ypJFWpUkWPPPLIRee3cOFCFRUV6dlnn1VAgPf/C/TldmnffPONDh06pGHDhnldG5yQkKDrrrtOS5YsKfaaoUOHej2//fbbvX6PYWFhys/PV1paWpnnA6B0CGAAl83x48e9YvNcf/nLX9SmTRsNGjRIdevWVc+ePfXRRx+VKYavuuqqMn3g7ZprrvF67nA4FBsb65frXy9k7969ioiIKPZ+NGrUyF7/W1dffXWxbdSqVUs///zzRfdzzTXXFIu98+3nUlWrVk1paWlKS0vTmjVrlJ2drS+++EL/9V//5TUuJiam2Gt37Nih5cuX2wF99tGpUydJZ65lPjvnevXqqWbNml6vb9iw4UXnt2vXLgUEBFzyh/3OOvv+lbTv6667rtj7W61atWKXlpz7exw2bJiuvfZade3aVZGRkRowYECpr/cGUDpcAwzgsti/f7/y8vIUGxt73jHBwcFas2aNMjIytGTJEi1fvlzz5s1Thw4dtHLlSlWpUuWi+ymPOwmc78xgYWFhqebkD+fbj3XOB+YqWpUqVexgvZCSfk9FRUW688479eSTT5b4mmuvvfaS51fRSvP34na7lZWVpRUrVmjZsmVatmyZ5syZowcffNDrw4sAfMcZYACXxXvvvSdJxf7Z+1wBAQHq2LGjpk2bpu+++04vvvii0tPTlZGRIcm3f6a+kB07dng9tyxLO3fu9LpjQ61atUq8w8C5Z/fKMrfo6GgdOHCg2CUh27Zts9f7Q3R0tHbs2FHsLLq/9+MPDRo00PHjx9WpU6cSH2fPgkdHR+vgwYM6fvy41+u3b99eqn0UFRXpu+++u+C40v4uz75/Je17+/btPr+/QUFBuuuuu/T6669r165deuihh/Tuu+9q586dPm0PgDcCGEC5S09P14QJExQTE6MHHnjgvOOOHDlSbNnZL5Q4+01iNWrUkKQSg9QX7777rleEzp8/XwcPHlTXrl3tZQ0aNND69ev166+/2ssWL15c7HZpZZlbt27dVFhYqFdffdVr+fTp0+VwOLz2fym6deumnJwczZs3z15WUFCgV155RTVr1lS7du38sh9/uP/++7Vu3TqtWLGi2LqjR4+qoKBA0pljKigo0BtvvGGvLyws1CuvvHLRffTo0UMBAQEaP358sf8o+O3Z9Bo1apTq93jzzTfL7XZr9uzZXt92t2zZMn3//fdKSEi46DbO9dNPP3k9DwgIsL9A5vf2jXpAZcUlEAD8atmyZdq2bZsKCgqUm5ur9PR0paWlKTo6Wp9++ukFv0Rg/PjxWrNmjRISEhQdHa1Dhw7p9ddfV2RkpG677TZJZ2I0LCxMs2fPVkhIiGrUqKFWrVqVeE1padSuXVu33Xab+vfvr9zcXM2YMUOxsbFet2obNGiQ5s+fry5duuj+++/Xrl279P7773t9KK2sc7vrrrt0xx136Omnn9aePXvUrFkzrVy5UosWLVJycnKxbftqyJAhevPNN5WYmKiNGzeqfv36mj9/vr744gvNmDHjgtdkX25PPPGEPv30U3Xv3l2JiYm66aablJ+fr3/961+aP3++9uzZozp16uiuu+5SmzZtNGbMGO3Zs0eNGzfWJ598ory8vIvuIzY2Vk8//bQmTJig22+/XX/605/kdDq1YcMGRUREKCUlRZJ000036Y033tBf//pXxcbGyu12q0OHDsW2V7VqVU2aNEn9+/dXu3bt1KtXL/s2aPXr19fIkSPL/D4MGjRIR44cUYcOHRQZGam9e/fqlVde0Y033mhfuw3gElXsTSgA/FGcvQ3a2UdQUJAVHh5u3XnnndbMmTO9brd11rm3qFq1apV1zz33WBEREVZQUJAVERFh9erVq9htsRYtWmQ1btzYCgwM9LrtVbt27azrr7++xPmd7zZo//u//2uNHTvWcrvdVnBwsJWQkGDt3bu32OunTp1qXXXVVZbT6bTatGljffPNN8W2eaG5nXsbNMuyrGPHjlkjR460IiIirKpVq1rXXHONNWXKFK/bcVnWmdugJSUlFZvT+W7Pdq7c3Fyrf//+Vp06daygoCCradOmJd6qzV+3QbuYC+3n2LFj1tixY63Y2FgrKCjIqlOnjtW6dWvr5Zdftn799Vd73E8//WT17dvXcrlcVmhoqNW3b19r06ZNF70N2llvv/221bx5c8vpdFq1atWy2rVrZ6Wlpdnrc3JyrISEBCskJMSSZP+ez70N2lnz5s2zt1e7dm3rgQcesPbv31+q9+fcOc6fP9/q3Lmz5Xa7raCgIOvqq6+2HnroIevgwYPnfU8BlI3DsirZJygAAACAcsQ1wAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKPwRRilUFRUpAMHDigkJMTvX8MKAACAS2dZlo4dO6aIiAgFBFz4HC8BXAoHDhxQVFRURU8DAAAAF5Gdna3IyMgLjiGAS+HsV4VmZ2fL5XJV8GwAAABwLo/Ho6ioqFJ9xTsBXApnL3twuVwEMAAAQCVWmstV+RAcAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoFRrAKSkpatmypUJCQuR2u9WjRw9t37692Lh169apQ4cOqlGjhlwul9q2bauTJ0/a648cOaIHHnhALpdLYWFhGjhwoI4fP+61jc2bN+v2229XtWrVFBUVpcmTJ5f78QEAAKDyqdAAXr16tZKSkrR+/XqlpaXp9OnT6ty5s/Lz8+0x69atU5cuXdS5c2d9/fXX2rBhg4YPH66AgP9M/YEHHtDWrVuVlpamxYsXa82aNRoyZIi93uPxqHPnzoqOjtbGjRs1ZcoUPf/88/rb3/52WY8XAAAAFc9hWZZV0ZM46/Dhw3K73Vq9erXatm0rSbr11lt15513asKECSW+5vvvv1fjxo21YcMG3XzzzZKk5cuXq1u3btq/f78iIiL0xhtv6Omnn1ZOTo6CgoIkSWPGjNHChQu1bdu2i87L4/EoNDRUeXl5crlcfjpaAAAA+EtZeq1SXQOcl5cnSapdu7Yk6dChQ/rqq6/kdrvVunVr1a1bV+3atdPatWvt16xbt05hYWF2/EpSp06dFBAQoK+++soe07ZtWzt+JSk+Pl7bt2/Xzz//XGwep06dksfj8XoAAADgj6HSBHBRUZGSk5PVpk0bNWnSRJL073//W5L0/PPPa/DgwVq+fLlatGihjh07aseOHZKknJwcud1ur20FBgaqdu3aysnJscfUrVvXa8zZ52fH/FZKSopCQ0PtR1RUlH8PFgAAABWm0gRwUlKStmzZog8//NBeVlRUJEl66KGH1L9/fzVv3lzTp09Xw4YN9fbbb5fbXMaOHau8vDz7kZ2dXW77AgAAwOUVWNETkKThw4fbH16LjIy0l9erV0+S1LhxY6/xjRo10r59+yRJ4eHhOnTokNf6goICHTlyROHh4faY3NxcrzFnn58d81tOp1NOp/MSjwoAAACVUYWeAbYsS8OHD9eCBQuUnp6umJgYr/X169dXREREsVuj/fDDD4qOjpYkxcXF6ejRo9q4caO9Pj09XUVFRWrVqpU9Zs2aNTp9+rQ9Ji0tTQ0bNlStWrXK6/AAAABQCVVoACclJen999/X3LlzFRISopycHOXk5Nj3+HU4HHriiSc0a9YszZ8/Xzt37tS4ceO0bds2DRw4UNKZs8FdunTR4MGD9fXXX+uLL77Q8OHD1bNnT0VEREiSevfuraCgIA0cOFBbt27VvHnzNHPmTI0aNarCjh0AAAAVo0Jvg+ZwOEpcPmfOHCUmJtrPX3rpJb322ms6cuSImjVrpsmTJ+u2226z1x85ckTDhw/XZ599poCAAN13332aNWuWatasaY/ZvHmzkpKStGHDBtWpU0ePPPKIRo8eXap5chs0AACAyq0svVap7gNcWRHAAAAAldvv9j7AAAAAQHkjgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYJQKDeCUlBS1bNlSISEhcrvd6tGjh7Zv3+41pn379nI4HF6PoUOHeo05d73D4dCHH37oNSYzM1MtWrSQ0+lUbGysUlNTy/vwAAAAUAlVaACvXr1aSUlJWr9+vdLS0nT69Gl17txZ+fn5XuMGDx6sgwcP2o/JkycX29acOXO8xvTo0cNet3v3biUkJOiOO+5QVlaWkpOTNWjQIK1YsaK8DxEAAACVTGBF7nz58uVez1NTU+V2u7Vx40a1bdvWXl69enWFh4dfcFthYWHnHTN79mzFxMRo6tSpkqRGjRpp7dq1mj59uuLj4y/xKAAAAPB7UqmuAc7Ly5Mk1a5d22v5Bx98oDp16qhJkyYaO3asTpw4Uey1SUlJqlOnjm655Ra9/fbbsizLXrdu3Tp16tTJa3x8fLzWrVtXDkcBAACAyqxCzwD/VlFRkZKTk9WmTRs1adLEXt67d29FR0crIiJCmzdv1ujRo7V9+3Z98skn9pjx48erQ4cOql69ulauXKlhw4bp+PHjGjFihCQpJydHdevW9dpf3bp15fF4dPLkSQUHB3utO3XqlE6dOmU/93g85XHIAAAAqACVJoCTkpK0ZcsWrV271mv5kCFD7J+bNm2qevXqqWPHjtq1a5caNGggSRo3bpw9pnnz5srPz9eUKVPsAC6rlJQUvfDCCz69FgAAAJVbpbgEYvjw4Vq8eLEyMjIUGRl5wbGtWrWSJO3cufOCY/bv32+fxQ0PD1dubq7XmNzcXLlcrmJnfyVp7NixysvLsx/Z2dllPSQAAABUUhV6BtiyLD3yyCNasGCBMjMzFRMTc9HXZGVlSZLq1at3wTG1atWS0+mUJMXFxWnp0qVeY9LS0hQXF1fi651Op/1aAAAA/LFUaAAnJSVp7ty5WrRokUJCQpSTkyNJCg0NVXBwsHbt2qW5c+eqW7duuuKKK7R582aNHDlSbdu21Q033CBJ+uyzz5Sbm6tbb71V1apVU1pamiZOnKjHH3/c3s/QoUP16quv6sknn9SAAQOUnp6ujz76SEuWLKmQ4wYAAEDFcVi/vV3C5d65w1Hi8jlz5igxMVHZ2dnq06ePtmzZovz8fEVFRenee+/VM888I5fLJenMrdTGjh2rnTt3yrIsxcbG6uGHH9bgwYMVEPCfKzwyMzM1cuRIfffdd4qMjNS4ceOUmJhYqnl6PB6FhoYqLy/P3i8AAAAqj7L0WoUG8O8FAQwAAFC5laXXKsWH4AAAAIDLhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABjFpwDOzs7W/v377edff/21kpOT9be//c1vEwMAAADKg08B3Lt3b2VkZEiScnJydOedd+rrr7/W008/rfHjx/t1ggAAAIA/+RTAW7Zs0S233CJJ+uijj9SkSRN9+eWX+uCDD5SamurP+QEAAAB+5VMAnz59Wk6nU5L0j3/8Q3fffbck6brrrtPBgwf9NzsAAADAz3wK4Ouvv16zZ8/W559/rrS0NHXp0kWSdODAAV1xxRV+nSAAAADgTz4F8KRJk/Tmm2+qffv26tWrl5o1ayZJ+vTTT+1LIwAAAIDKyGFZluXLCwsLC+XxeFSrVi172Z49e1S9enW53W6/TbAy8Hg8Cg0NVV5enlwuV0VPBwAAAOcoS68F+rqTKlWqeMWvJNWvX9/XzQEAAACXhU+XQOTm5qpv376KiIhQYGCgqlSp4vUAAAAAKiufzgAnJiZq3759GjdunOrVqyeHw+HveQEAAADlwqcAXrt2rT7//HPdeOONfp4OAAAAUL58ugQiKipKPn52DgAAAKhQPgXwjBkzNGbMGO3Zs8fP0wEAAADKl0+XQPzlL3/RiRMn1KBBA1WvXl1Vq1b1Wn/kyBG/TA4AAADwN58CeMaMGX6eBgAAAHB5+BTA/fr18/c8AAAAgMvC5y/CKCws1MKFC/X9999Lkq6//nrdfffd3AcYAAAAlZpPAbxz505169ZNP/74oxo2bChJSklJUVRUlJYsWaIGDRr4dZIAAACAv/h0F4gRI0aoQYMGys7O1j//+U/985//1L59+xQTE6MRI0b4e44AAACA3/h0Bnj16tVav369ateubS+74oor9NJLL6lNmzZ+mxwAAADgbz6dAXY6nTp27Fix5cePH1dQUNAlTwoAAAAoLz4FcPfu3TVkyBB99dVXsixLlmVp/fr1Gjp0qO6++25/zxEAAADwG58CeNasWWrQoIHi4uJUrVo1VatWTW3atFFsbKxmzpzp7zkCAAAAfuPTNcBhYWFatGiRduzYoW3btkmSGjVqpNjYWL9ODgAAAPA3n+8DLEnXXHONrrnmGn/NBQAAACh3pQ7gUaNGacKECapRo4ZGjRp1wbHTpk275IkBAAAA5aHUAbxp0yadPn3a/hkAAAD4PXJYlmVV9CQqO4/Ho9DQUOXl5cnlclX0dAAAAHCOsvSaT3eBGDBgQIn3Ac7Pz9eAAQN82SQAAABwWfgUwO+8845OnjxZbPnJkyf17rvvXvKkAAAAgPJSprtAeDwe+4svjh07pmrVqtnrCgsLtXTpUrndbr9PEgAAAPCXMgVwWFiYHA6HHA6Hrr322mLrHQ6HXnjhBb9NDgAAAPC3MgVwRkaGLMtShw4d9Pe//121a9e21wUFBSk6OloRERF+nyQAAADgL2UK4Hbt2kmSdu/erauvvloOh6NcJgUAAACUF5++CS49PV01a9bUf//3f3st//jjj3XixAn169fPL5NDxWrfvn1FTwGAn73++uslLh82bNhlngmA8paZmVnRU6i0fLoLREpKiurUqVNsudvt1sSJEy95UgAAAEB58ekM8L59+xQTE1NseXR0tPbt23fJk0LlwH85Aubg/94BmMSnM8But1ubN28utvzbb7/VFVdcccmTAgAAAMqLTwHcq1cvjRgxQhkZGSosLFRhYaHS09P16KOPqmfPnv6eIwAAAOA3Pl0CMWHCBO3Zs0cdO3ZUYOCZTRQVFenBBx/kGmAAAABUag7LsixfX/zDDz/o22+/VXBwsJo2baro6Gh/zq3S8Hg8Cg0NVV5enlwuV0VPBwAAAOcoS6/5dAb4rGuvvbbEb4QDAAAAKqtSB/CoUaM0YcIE1ahRQ6NGjbrg2GnTpl3yxAAAAIDyUOoA3rRpk06fPm3/fD58OxwAAAAqs1LfBSIjI0NhYWH2z+d7pKenl3rnKSkpatmypUJCQuR2u9WjRw9t377da0z79u3lcDi8HkOHDvUas2/fPiUkJKh69epyu9164oknVFBQ4DUmMzNTLVq0kNPpVGxsrFJTU0s9TwAAAPxx+HQbNH9ZvXq1kpKStH79eqWlpen06dPq3Lmz8vPzvcYNHjxYBw8etB+TJ0+21xUWFiohIUG//vqrvvzyS73zzjtKTU3Vs88+a4/ZvXu3EhISdMcddygrK0vJyckaNGiQVqxYcdmOFQAAAJVDqe8C8ac//anUG/3kk098mszhw4fldru1evVqtW3bVtKZM8A33nijZsyYUeJrli1bpu7du+vAgQOqW7euJGn27NkaPXq0Dh8+rKCgII0ePVpLlizRli1b7Nf17NlTR48e1fLlyy86L+4CAQAAULmVpddKfQY4NDTUfrhcLq1atUrffPONvX7jxo1atWqVQkNDfZ54Xl6eJKl27dpeyz/44APVqVNHTZo00dixY3XixAl73bp169S0aVM7fiUpPj5eHo9HW7dutcd06tTJa5vx8fFat26dz3MFAADA71OpPwQ3Z84c++fRo0fr/vvv1+zZs1WlShVJZy5FGDZsmM9nSIuKipScnKw2bdqoSZMm9vLevXsrOjpaERER2rx5s0aPHq3t27fbZ5lzcnK84leS/TwnJ+eCYzwej06ePKng4GCvdadOndKpU6fs5x6Px6djAgAAQOXj032A3377ba1du9aOX0mqUqWKRo0apdatW2vKlCll3mZSUpK2bNmitWvXei0fMmSI/XPTpk1Vr149dezYUbt27VKDBg18mf5FpaSk6IUXXiiXbQMAAKBi+fQhuIKCAm3btq3Y8m3btqmoqKjM2xs+fLgWL16sjIwMRUZGXnBsq1atJEk7d+6UJIWHhys3N9drzNnn4eHhFxzjcrmKnf2VpLFjxyovL89+ZGdnl/mYAAAAUDn5dAa4f//+GjhwoHbt2qVbbrlFkvTVV1/ppZdeUv/+/Uu9Hcuy9Mgjj2jBggXKzMxUTEzMRV+TlZUlSapXr54kKS4uTi+++KIOHTokt9stSUpLS5PL5VLjxo3tMUuXLvXaTlpamuLi4krch9PplNPpLPVxAAAA4Pej1HeB+K2ioiK9/PLLmjlzpg4ePCjpTJA++uijeuyxx7wujbiQYcOGae7cuVq0aJEaNmxoLw8NDVVwcLB27dqluXPnqlu3brriiiu0efNmjRw5UpGRkVq9erWkM9ce33jjjYqIiNDkyZOVk5Ojvn37atCgQZo4caKkM7dBa9KkiZKSkjRgwAClp6drxIgRWrJkieLj4y86T+4CAQAAULmVpdd8CuBzdybJpzA837fGzZkzR4mJicrOzlafPn20ZcsW5efnKyoqSvfee6+eeeYZr/3t3btXDz/8sDIzM1WjRg3169dPL730kgID/3OCOzMzUyNHjtR3332nyMhIjRs3TomJiaU+RgIYAACg8rosAVxQUKDMzEzt2rVLvXv3VkhIiA4cOCCXy6WaNWv6NPHKigAGAACo3MrSaz5dA7x371516dJF+/bt06lTp3TnnXcqJCREkyZN0qlTpzR79myfJg4AAACUN5/uAvHoo4/q5ptv1s8//+x1F4V7771Xq1at8tvkAAAAAH/z6Qzw559/ri+//FJBQUFey+vXr68ff/zRLxMDAAAAyoNPZ4CLiopUWFhYbPn+/fsVEhJyyZMCAAAAyotPAdy5c2fNmDHDfu5wOHT8+HE999xz6tatm7/mBgAAAPidT3eByM7OVpcuXWRZlnbs2KGbb75ZO3bsUJ06dbRmzRr7Cyn+KLgLBAAAQOV22W6DNm/ePH377bc6fvy4WrRooQceeKDErxb+vSOAAQAAKrdyDeDTp0/ruuuu0+LFi9WoUaNLmujvBQEMAABQuZWl18p8DXDVqlX1yy+/+Dw5AAAAoCL59CG4pKQkTZo0SQUFBf6eDwAAAFCufLoP8IYNG7Rq1SqtXLlSTZs2VY0aNbzWf/LJJ36ZHAAAAOBvPgVwWFiY7rvvPn/PBQAAACh3ZQrgoqIiTZkyRT/88IN+/fVXdejQQc8///wf8s4PAAAA+GMq0zXAL774op566inVrFlTV111lWbNmqWkpKTymhsAAADgd2UK4HfffVevv/66VqxYoYULF+qzzz7TBx98oKKiovKaHwAAAOBXZQrgffv2eX3VcadOneRwOHTgwAG/TwwAAAAoD2UK4IKCAlWrVs1rWdWqVXX69Gm/TgoAAAAoL2X6EJxlWUpMTJTT6bSX/fLLLxo6dKjXrdC4DRoAAAAqqzIFcL9+/Yot69Onj98mAwAAAJS3MgXwnDlzymseAAAAwGXh01chAwAAAL9XBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgVGsApKSlq2bKlQkJC5Ha71aNHD23fvr3EsZZlqWvXrnI4HFq4cKHXOofDUezx4Ycfeo3JzMxUixYt5HQ6FRsbq9TU1HI6KgAAAFRmFRrAq1evVlJSktavX6+0tDSdPn1anTt3Vn5+frGxM2bMkMPhOO+25syZo4MHD9qPHj162Ot2796thIQE3XHHHcrKylJycrIGDRqkFStWlMdhAQAAoBILrMidL1++3Ot5amqq3G63Nm7cqLZt29rLs7KyNHXqVH3zzTeqV69eidsKCwtTeHh4ietmz56tmJgYTZ06VZLUqFEjrV27VtOnT1d8fLyfjgYAAAC/B5XqGuC8vDxJUu3ate1lJ06cUO/evfXaa6+dN3AlKSkpSXXq1NEtt9yit99+W5Zl2evWrVunTp06eY2Pj4/XunXrStzWqVOn5PF4vB4AAAD4Y6jQM8C/VVRUpOTkZLVp00ZNmjSxl48cOVKtW7fWPffcc97Xjh8/Xh06dFD16tW1cuVKDRs2TMePH9eIESMkSTk5Oapbt67Xa+rWrSuPx6OTJ08qODjYa11KSopeeOEFPx4dAAAAKotKE8BJSUnasmWL1q5day/79NNPlZ6erk2bNl3wtePGjbN/bt68ufLz8zVlyhQ7gMtq7NixGjVqlP3c4/EoKirKp20BAACgcqkUl0AMHz5cixcvVkZGhiIjI+3l6enp2rVrl8LCwhQYGKjAwDO9ft9996l9+/bn3V6rVq20f/9+nTp1SpIUHh6u3NxcrzG5ublyuVzFzv5KktPplMvl8noAAADgj6FCzwBblqVHHnlECxYsUGZmpmJiYrzWjxkzRoMGDfJa1rRpU02fPl133XXXebeblZWlWrVqyel0SpLi4uK0dOlSrzFpaWmKi4vz05EAAADg96JCAzgpKUlz587VokWLFBISopycHElSaGiogoODFR4eXuIH366++mo7lj/77DPl5ubq1ltvVbVq1ZSWlqaJEyfq8ccft8cPHTpUr776qp588kkNGDBA6enp+uijj7RkyZLLc6AAAACoNCo0gN944w1JKnY5w5w5c5SYmFiqbVStWlWvvfaaRo4cKcuyFBsbq2nTpmnw4MH2mJiYGC1ZskQjR47UzJkzFRkZqbfeeotboAEAABjIYf32fmEokcfjUWhoqPLy8rgeGAAAoBIqS69Vig/BAQAAAJcLAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADBKhQZwSkqKWrZsqZCQELndbvXo0UPbt28vcaxlWeratascDocWLlzotW7fvn1KSEhQ9erV5Xa79cQTT6igoMBrTGZmplq0aCGn06nY2FilpqaW01EBAACgMqvQAF69erWSkpK0fv16paWl6fTp0+rcubPy8/OLjZ0xY4YcDkex5YWFhUpISNCvv/6qL7/8Uu+8845SU1P17LPP2mN2796thIQE3XHHHcrKylJycrIGDRqkFStWlOvxAQAAoPJxWJZlVfQkzjp8+LDcbrdWr16ttm3b2suzsrLUvXt3ffPNN6pXr54WLFigHj16SJKWLVum7t2768CBA6pbt64kafbs2Ro9erQOHz6soKAgjR49WkuWLNGWLVvsbfbs2VNHjx7V8uXLLzovj8ej0NBQ5eXlyeVy+fegAQAAcMnK0muV6hrgvLw8SVLt2rXtZSdOnFDv3r312muvKTw8vNhr1q1bp6ZNm9rxK0nx8fHyeDzaunWrPaZTp05er4uPj9e6detKnMepU6fk8Xi8HgAAAPhjqDQBXFRUpOTkZLVp00ZNmjSxl48cOVKtW7fWPffcU+LrcnJyvOJXkv08JyfngmM8Ho9OnjxZbJspKSkKDQ21H1FRUZd0bAAAAKg8Ait6AmclJSVpy5YtWrt2rb3s008/VXp6ujZt2nRZ5zJ27FiNGjXKfu7xeIhgAACAP4hKcQZ4+PDhWrx4sTIyMhQZGWkvT09P165duxQWFqbAwEAFBp7p9fvuu0/t27eXJIWHhys3N9dre2efn71k4nxjXC6XgoODi83H6XTK5XJ5PQAAAPDHUKEBbFmWhg8frgULFig9PV0xMTFe68eMGaPNmzcrKyvLfkjS9OnTNWfOHElSXFyc/vWvf+nQoUP269LS0uRyudS4cWN7zKpVq7y2nZaWpri4uHI8OgAAAFRGFXoJRFJSkubOnatFixYpJCTEvmY3NDRUwcHBCg8PL/GDb1dffbUdy507d1bjxo3Vt29fTZ48WTk5OXrmmWeUlJQkp9MpSRo6dKheffVVPfnkkxowYIDS09P10UcfacmSJZfvYAEAAFApVOgZ4DfeeEN5eXlq37696tWrZz/mzZtX6m1UqVJFixcvVpUqVRQXF6c+ffrowQcf1Pjx4+0xMTExWrJkidLS0tSsWTNNnTpVb731luLj48vjsAAAAFCJVar7AFdW3AcYAACgcvvd3gcYAAAAKG8EMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjBJY0RP4PbAsS5Lk8XgqeCYAAAAoydlOO9ttF0IAl8KxY8ckSVFRURU8EwAAAFzIsWPHFBoaesExDqs0mWy4oqIiHThwQCEhIXI4HBU9HQC4ZB6PR1FRUcrOzpbL5aro6QDAJbMsS8eOHVNERIQCAi58lS8BDAAG8ng8Cg0NVV5eHgEMwDh8CA4AAABGIYABAABgFAIYAAzkdDr13HPPyel0VvRUAOCy4xpgAAAAGIUzwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACj/D90pClO2C6DDQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real: shape: torch.Size([100]), goal val: 2508.0\n",
      "min: 2508.0, max: 2508.0, mean: 2508.0, std: 0.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TODO good enough for now\n",
    "device = 'cpu'\n",
    "\n",
    "test_dataset = GPTDataset(files=['exchange_rate.txt'], window=block_size) # TODO why does this need to be the same size\n",
    "\n",
    "# Generate text\n",
    "output = model_for_trainer.generate(\n",
    "    test_dataset[0]['input_ids'].unsqueeze(0),\n",
    "    # max_length=512,\n",
    "    max_new_tokens=1,\n",
    "    # temperature=0.7,\n",
    "    # num_return_sequences=1,\n",
    "    # pad_token_id=vocab_size - 1,\n",
    "    # do_sample=True\n",
    ")\n",
    "\n",
    "torch.set_printoptions(profile='full')\n",
    "print('start')\n",
    "print('real',test_dataset[0]['labels'][:32])\n",
    "print('pred',output[0][1:33])\n",
    "print('middle (1020:1050)')\n",
    "print('real',test_dataset[0]['labels'][1000:1050])\n",
    "print('pred',output[0][1001:1051])\n",
    "print('end')\n",
    "print('real',test_dataset[0]['labels'][-32:])\n",
    "print('pred',output[0][-32:])\n",
    "torch.set_printoptions(profile='default')\n",
    "\n",
    "# create scatter plot\n",
    "n = 100\n",
    "m = 1\n",
    "\n",
    "# not sure how to line up the real and pred when using different size. so i will just change dataset size\n",
    "real = torch.full_like(torch.zeros(n), test_dataset[0]['labels'][-1])\n",
    "pred = torch.zeros(n)\n",
    "\n",
    "pbar = tqdm(range(0, n, m), total=n)\n",
    "for i in pbar:\n",
    "    output = model_for_trainer.generate(\n",
    "        test_dataset[0]['input_ids'][:block_size].unsqueeze(0),\n",
    "        max_new_tokens=1,\n",
    "    )\n",
    "\n",
    "    for j in range(m): # -1\n",
    "        pred[i+j] = output[j][-1].cpu() # have to do this to get the value\n",
    "    pbar.update(m)\n",
    "\n",
    "# create scatter plot\n",
    "plt.scatter(range(n), real, label='real')\n",
    "plt.scatter(range(n), pred, label='pred')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame({'Predictions': pred})\n",
    "\n",
    "# Create the violin plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.violinplot(y='Predictions', data=df)\n",
    "plt.title(f\"Distribution of  Predictions\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"real: shape: {real.shape}, goal val: {real[0]}\")\n",
    "print(f\"min: {min(pred)}, max: {max(pred)}, mean: {torch.mean(pred)}, std: {torch.std(pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▋                                                                            | 6/75 [00:01<00:14,  4.77it/s]"
     ]
    }
   ],
   "source": [
    "# create scatter plot\n",
    "n = 100\n",
    "m = 1\n",
    "\n",
    "if n >= len(test_dataset)-1:\n",
    "    n = len(test_dataset)-1\n",
    "\n",
    "# not sure how to line up the real and pred when using different size. so i will just change dataset size\n",
    "real = torch.zeros(n)\n",
    "pred = torch.zeros(n)\n",
    "\n",
    "pbar = tqdm(range(0, n, m), total=n)\n",
    "for i in pbar:\n",
    "    output = model_for_trainer.generate(\n",
    "        test_dataset[i]['input_ids'][:block_size].unsqueeze(0),\n",
    "        max_new_tokens=1,\n",
    "    )\n",
    "\n",
    "    for j in range(m): # -1\n",
    "        real[i+j] = test_dataset[i]['labels'][-1]\n",
    "        pred[i+j] = output[j][-1].cpu() # have to do this to get the value\n",
    "    pbar.update(m)\n",
    "\n",
    "# create scatter plot\n",
    "plt.scatter(range(n), real, label='real')\n",
    "plt.scatter(range(n), pred, label='pred')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
